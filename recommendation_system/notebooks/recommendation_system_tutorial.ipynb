{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Production-Grade Recommendation System Tutorial\n",
    "\n",
    "**Complete End-to-End Implementation for Staff-Level ML Interviews**\n",
    "\n",
    "This notebook covers:\n",
    "1. Data Generation & Processing\n",
    "2. Feature Engineering\n",
    "3. Embedding Models (5 strategies)\n",
    "4. Ranking Models (LightGBM, DCN, DeepFM)\n",
    "5. Production Serving Architecture\n",
    "6. Monitoring & A/B Testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Data Generation & Exploration\n",
    "\n",
    "### Key Interview Topic: Data Characteristics in RecSys\n",
    "- **Implicit vs Explicit Feedback**\n",
    "- **Sparsity** (99.9% of user-item pairs have no interaction)\n",
    "- **Power Law Distribution** (few popular items, long tail)\n",
    "- **Temporal Patterns** (seasonality, trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic user-item interactions\n",
    "num_users = 10000\n",
    "num_items = 5000\n",
    "num_interactions = 100000\n",
    "\n",
    "print(f\"Generating dataset:\")\n",
    "print(f\"  - Users: {num_users:,}\")\n",
    "print(f\"  - Items: {num_items:,}\")\n",
    "print(f\"  - Interactions: {num_interactions:,}\")\n",
    "print(f\"  - Sparsity: {100 * (1 - num_interactions/(num_users*num_items)):.2f}%\")\n",
    "\n",
    "# Create interactions with realistic distribution\n",
    "# Power law: few users/items are very active/popular\n",
    "user_activity = np.random.power(0.5, num_users)  # Power law\n",
    "user_probs = user_activity / user_activity.sum()\n",
    "\n",
    "item_popularity = np.random.power(0.5, num_items)\n",
    "item_probs = item_popularity / item_popularity.sum()\n",
    "\n",
    "interactions_df = pd.DataFrame({\n",
    "    'user_id': np.random.choice(num_users, num_interactions, p=user_probs),\n",
    "    'item_id': np.random.choice(num_items, num_interactions, p=item_probs),\n",
    "    'timestamp': [datetime.now() - timedelta(days=np.random.randint(0, 90)) \n",
    "                  for _ in range(num_interactions)],\n",
    "    'event_type': np.random.choice(\n",
    "        ['view', 'click', 'add_to_cart', 'purchase'],\n",
    "        num_interactions,\n",
    "        p=[0.6, 0.25, 0.1, 0.05]\n",
    "    )\n",
    "})\n",
    "\n",
    "# Add explicit ratings for some interactions\n",
    "interactions_df['rating'] = np.random.randint(1, 6, num_interactions)\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {len(interactions_df):,} interactions\")\n",
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Data Exploration & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Event type distribution\n",
    "event_counts = interactions_df['event_type'].value_counts()\n",
    "axes[0, 0].bar(event_counts.index, event_counts.values, color='skyblue')\n",
    "axes[0, 0].set_title('Event Type Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. User activity distribution (power law)\n",
    "user_counts = interactions_df['user_id'].value_counts().values\n",
    "axes[0, 1].hist(user_counts, bins=50, color='coral', alpha=0.7)\n",
    "axes[0, 1].set_title('User Activity Distribution (Power Law)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Interactions per User')\n",
    "axes[0, 1].set_ylabel('Number of Users')\n",
    "axes[0, 1].set_yscale('log')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Item popularity distribution\n",
    "item_counts = interactions_df['item_id'].value_counts().values\n",
    "axes[1, 0].hist(item_counts, bins=50, color='lightgreen', alpha=0.7)\n",
    "axes[1, 0].set_title('Item Popularity Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Interactions per Item')\n",
    "axes[1, 0].set_ylabel('Number of Items')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 4. Temporal pattern\n",
    "interactions_df['date'] = interactions_df['timestamp'].dt.date\n",
    "daily_counts = interactions_df.groupby('date').size()\n",
    "axes[1, 1].plot(daily_counts.index, daily_counts.values, marker='o', linewidth=2, markersize=4)\n",
    "axes[1, 1].set_title('Daily Interaction Volume', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Interactions')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Statistics:\")\n",
    "print(f\"  - Most active user: {user_counts.max()} interactions\")\n",
    "print(f\"  - Most popular item: {item_counts.max()} interactions\")\n",
    "print(f\"  - Avg interactions per user: {user_counts.mean():.1f}\")\n",
    "print(f\"  - Avg interactions per item: {item_counts.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ Feature Engineering\n",
    "\n",
    "### Interview Topic: What makes good features?\n",
    "- **User Features**: Demographics, behavior, preferences\n",
    "- **Item Features**: Metadata, popularity, quality\n",
    "- **Context Features**: Time, device, location\n",
    "- **Interaction Features**: User-item affinity, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Features\n",
    "print(\"üîß Engineering User Features...\")\n",
    "\n",
    "user_features = interactions_df.groupby('user_id').agg({\n",
    "    'item_id': 'count',  # Total interactions\n",
    "    'timestamp': ['min', 'max'],  # First and last interaction\n",
    "    'rating': 'mean'  # Average rating given\n",
    "}).reset_index()\n",
    "\n",
    "user_features.columns = ['user_id', 'total_interactions', 'first_seen', 'last_seen', 'avg_rating']\n",
    "\n",
    "# Derived features\n",
    "user_features['recency_days'] = (datetime.now() - user_features['last_seen']).dt.days\n",
    "user_features['tenure_days'] = (user_features['last_seen'] - user_features['first_seen']).dt.days\n",
    "user_features['activity_rate'] = user_features['total_interactions'] / (user_features['tenure_days'] + 1)\n",
    "\n",
    "# Event type distribution per user\n",
    "event_dist = interactions_df.groupby(['user_id', 'event_type']).size().unstack(fill_value=0)\n",
    "event_dist.columns = [f'{col}_count' for col in event_dist.columns]\n",
    "user_features = user_features.merge(event_dist, on='user_id', how='left').fillna(0)\n",
    "\n",
    "# Conversion rate\n",
    "user_features['conversion_rate'] = user_features['purchase_count'] / (user_features['click_count'] + 1)\n",
    "\n",
    "print(f\"‚úÖ Created {len(user_features)} user feature vectors\")\n",
    "print(f\"   Features: {list(user_features.columns)}\")\n",
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item Features\n",
    "print(\"üîß Engineering Item Features...\")\n",
    "\n",
    "item_features = interactions_df.groupby('item_id').agg({\n",
    "    'user_id': 'count',  # Total views\n",
    "    'rating': 'mean',  # Average rating\n",
    "    'timestamp': 'max'  # Last interaction\n",
    "}).reset_index()\n",
    "\n",
    "item_features.columns = ['item_id', 'popularity', 'avg_rating', 'last_interaction']\n",
    "\n",
    "# Derived features\n",
    "item_features['log_popularity'] = np.log1p(item_features['popularity'])\n",
    "item_features['days_since_interaction'] = (datetime.now() - item_features['last_interaction']).dt.days\n",
    "\n",
    "# Event conversion metrics per item\n",
    "item_events = interactions_df.groupby(['item_id', 'event_type']).size().unstack(fill_value=0)\n",
    "item_events['ctr'] = item_events['click'] / (item_events['view'] + 1)\n",
    "item_events['conversion_rate'] = item_events['purchase'] / (item_events['click'] + 1)\n",
    "\n",
    "item_features = item_features.merge(\n",
    "    item_events[['ctr', 'conversion_rate']], \n",
    "    on='item_id', \n",
    "    how='left'\n",
    ").fillna(0)\n",
    "\n",
    "print(f\"‚úÖ Created {len(item_features)} item feature vectors\")\n",
    "print(f\"   Features: {list(item_features.columns)}\")\n",
    "item_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user feature correlations\n",
    "numeric_cols = user_features.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = user_features[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('User Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interview Insight:\")\n",
    "print(\"High correlations (>0.7) indicate redundant features.\")\n",
    "print(\"Consider PCA or feature selection for efficiency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ Train/Test Split\n",
    "\n",
    "### Interview Topic: Why Time-Based Split?\n",
    "- ‚ùå **Random split**: Data leakage (using future to predict past)\n",
    "- ‚úÖ **Time-based split**: Realistic (predict future from past)\n",
    "- Simulates production scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split: last 7 days for test\n",
    "cutoff_date = datetime.now() - timedelta(days=7)\n",
    "\n",
    "train_df = interactions_df[interactions_df['timestamp'] < cutoff_date].copy()\n",
    "test_df = interactions_df[interactions_df['timestamp'] >= cutoff_date].copy()\n",
    "\n",
    "print(f\"üìä Dataset Split:\")\n",
    "print(f\"  - Train: {len(train_df):,} interactions ({len(train_df)/len(interactions_df)*100:.1f}%)\")\n",
    "print(f\"  - Test:  {len(test_df):,} interactions ({len(test_df)/len(interactions_df)*100:.1f}%)\")\n",
    "print(f\"\\n  - Train date range: {train_df['timestamp'].min()} to {train_df['timestamp'].max()}\")\n",
    "print(f\"  - Test date range:  {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "\n",
    "# Visualize split\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "train_daily = train_df.groupby(train_df['timestamp'].dt.date).size()\n",
    "test_daily = test_df.groupby(test_df['timestamp'].dt.date).size()\n",
    "\n",
    "ax.bar(train_daily.index, train_daily.values, label='Train', alpha=0.7, color='steelblue')\n",
    "ax.bar(test_daily.index, test_daily.values, label='Test', alpha=0.7, color='coral')\n",
    "ax.axvline(cutoff_date.date(), color='red', linestyle='--', linewidth=2, label='Split Point')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Interactions')\n",
    "ax.set_title('Time-Based Train/Test Split', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ Embedding Models\n",
    "\n",
    "### Strategy 1: Matrix Factorization (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    \"\"\"\n",
    "    Classic Matrix Factorization (SVD-based)\n",
    "    \n",
    "    Interview Point: When to use MF vs Deep Learning?\n",
    "    - MF: Simple, interpretable, good baseline\n",
    "    - DL: Better for complex patterns, side information\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        # Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.user_embeddings.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embeddings.weight)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "    \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_emb = self.user_embeddings(user_ids)\n",
    "        item_emb = self.item_embeddings(item_ids)\n",
    "        \n",
    "        # Dot product + biases\n",
    "        scores = (user_emb * item_emb).sum(dim=1)\n",
    "        scores += self.user_bias(user_ids).squeeze()\n",
    "        scores += self.item_bias(item_ids).squeeze()\n",
    "        scores += self.global_bias\n",
    "        \n",
    "        return scores\n",
    "\n",
    "# Initialize model\n",
    "embedding_dim = 64\n",
    "mf_model = MatrixFactorization(num_users, num_items, embedding_dim)\n",
    "\n",
    "print(f\"‚úÖ Matrix Factorization Model Created\")\n",
    "print(f\"   - Users: {num_users:,}\")\n",
    "print(f\"   - Items: {num_items:,}\")\n",
    "print(f\"   - Embedding dim: {embedding_dim}\")\n",
    "print(f\"   - Parameters: {sum(p.numel() for p in mf_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "train_users = torch.LongTensor(train_df['user_id'].values)\n",
    "train_items = torch.LongTensor(train_df['item_id'].values)\n",
    "train_ratings = torch.FloatTensor(train_df['rating'].values)\n",
    "\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(mf_model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "batch_size = 1024\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "\n",
    "print(\"üöÄ Training Matrix Factorization...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    mf_model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batches = len(train_df) // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        batch_users = train_users[start_idx:end_idx]\n",
    "        batch_items = train_items[start_idx:end_idx]\n",
    "        batch_ratings = train_ratings[start_idx:end_idx]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = mf_model(batch_users, batch_items)\n",
    "        loss = criterion(predictions, batch_ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Matrix Factorization Training Curve', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Training Complete! Final Loss: {train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract & Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "mf_model.eval()\n",
    "with torch.no_grad():\n",
    "    user_embeddings = mf_model.user_embeddings.weight.numpy()\n",
    "    item_embeddings = mf_model.item_embeddings.weight.numpy()\n",
    "\n",
    "print(f\"üìä Embedding Shapes:\")\n",
    "print(f\"  - User embeddings: {user_embeddings.shape}\")\n",
    "print(f\"  - Item embeddings: {item_embeddings.shape}\")\n",
    "\n",
    "# Visualize embedding distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# User embeddings\n",
    "axes[0].hist(user_embeddings.flatten(), bins=50, alpha=0.7, color='steelblue')\n",
    "axes[0].set_title('User Embedding Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Embedding Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Item embeddings\n",
    "axes[1].hist(item_embeddings.flatten(), bins=50, alpha=0.7, color='coral')\n",
    "axes[1].set_title('Item Embedding Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Embedding Value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà Embedding Statistics:\")\n",
    "print(f\"  User embeddings - Mean: {user_embeddings.mean():.4f}, Std: {user_embeddings.std():.4f}\")\n",
    "print(f\"  Item embeddings - Mean: {item_embeddings.mean():.4f}, Std: {item_embeddings.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2: Two-Tower Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Two-Tower Architecture (Industry Standard)\n",
    "    \n",
    "    Interview Point: Why Two-Tower?\n",
    "    - Separate user/item encoding\n",
    "    - Cache item embeddings (static)\n",
    "    - Fast serving with ANN search\n",
    "    - Used by YouTube, Google, Meta\n",
    "    \"\"\"\n",
    "    def __init__(self, user_feature_dim, item_feature_dim, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # User tower\n",
    "        self.user_tower = nn.Sequential(\n",
    "            nn.Linear(user_feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        # Item tower\n",
    "        self.item_tower = nn.Sequential(\n",
    "            nn.Linear(item_feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        # Temperature for scaling\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 0.07)\n",
    "    \n",
    "    def forward(self, user_features, item_features):\n",
    "        user_emb = self.user_tower(user_features)\n",
    "        item_emb = self.item_tower(item_features)\n",
    "        \n",
    "        # L2 normalize (crucial for cosine similarity)\n",
    "        user_emb = F.normalize(user_emb, p=2, dim=1)\n",
    "        item_emb = F.normalize(item_emb, p=2, dim=1)\n",
    "        \n",
    "        # Dot product similarity\n",
    "        scores = (user_emb * item_emb).sum(dim=1) / self.temperature\n",
    "        return scores\n",
    "\n",
    "# Example initialization\n",
    "two_tower = TwoTowerModel(user_feature_dim=10, item_feature_dim=8, embedding_dim=128)\n",
    "\n",
    "print(\"‚úÖ Two-Tower Model Created\")\n",
    "print(f\"   - Parameters: {sum(p.numel() for p in two_tower.parameters()):,}\")\n",
    "print(f\"\\nüí° Key Advantage: Item embeddings can be pre-computed and cached!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Candidate Generation with ANN Search\n",
    "\n",
    "### Interview Topic: Why ANN (Approximate Nearest Neighbor)?\n",
    "- **Brute force**: O(n) - too slow for millions of items\n",
    "- **ANN**: O(log n) - sub-linear search\n",
    "- **FAISS**: GPU-accelerated, 10M items in <20ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_similar_items(user_emb, item_embs, k=50):\n",
    "    \"\"\"\n",
    "    Retrieve top-k similar items using cosine similarity\n",
    "    \n",
    "    In production: Use FAISS for sub-linear search\n",
    "    \"\"\"\n",
    "    # Normalize embeddings\n",
    "    user_emb_norm = user_emb / np.linalg.norm(user_emb)\n",
    "    item_embs_norm = item_embs / np.linalg.norm(item_embs, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    similarities = item_embs_norm @ user_emb_norm\n",
    "    \n",
    "    # Get top-k\n",
    "    top_k_indices = np.argsort(-similarities)[:k]\n",
    "    top_k_scores = similarities[top_k_indices]\n",
    "    \n",
    "    return top_k_indices, top_k_scores\n",
    "\n",
    "# Example: Get recommendations for user 0\n",
    "test_user_id = 0\n",
    "test_user_emb = user_embeddings[test_user_id]\n",
    "\n",
    "candidate_items, candidate_scores = get_top_k_similar_items(\n",
    "    test_user_emb, \n",
    "    item_embeddings, \n",
    "    k=50\n",
    ")\n",
    "\n",
    "print(f\"üéØ Generated {len(candidate_items)} candidates for User {test_user_id}\")\n",
    "print(f\"\\nTop 10 recommendations:\")\n",
    "print(f\"{'Rank':<6} {'Item ID':<10} {'Score':<10}\")\n",
    "print(\"-\" * 30)\n",
    "for i, (item_id, score) in enumerate(zip(candidate_items[:10], candidate_scores[:10]), 1):\n",
    "    print(f\"{i:<6} {item_id:<10} {score:.4f}\")\n",
    "\n",
    "# Visualize score distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(candidate_scores)), candidate_scores, color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Candidate Rank')\n",
    "plt.ylabel('Similarity Score')\n",
    "plt.title(f'Candidate Scores for User {test_user_id}', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Evaluation Metrics\n",
    "\n",
    "### Interview Topic: What metrics matter for RecSys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, actuals, k=10):\n",
    "    \"\"\"\n",
    "    Compute ranking metrics\n",
    "    \n",
    "    Metrics:\n",
    "    - Precision@K: % of recommended items that are relevant\n",
    "    - Recall@K: % of relevant items that are recommended\n",
    "    - NDCG@K: Normalized Discounted Cumulative Gain (position-aware)\n",
    "    \"\"\"\n",
    "    relevant = set(actuals)\n",
    "    recommended = set(predictions[:k])\n",
    "    \n",
    "    # Precision@K\n",
    "    precision = len(relevant & recommended) / k if k > 0 else 0\n",
    "    \n",
    "    # Recall@K\n",
    "    recall = len(relevant & recommended) / len(relevant) if len(relevant) > 0 else 0\n",
    "    \n",
    "    # NDCG@K\n",
    "    dcg = sum([1.0 / np.log2(i + 2) if predictions[i] in relevant else 0\n",
    "               for i in range(min(k, len(predictions)))])\n",
    "    idcg = sum([1.0 / np.log2(i + 2) for i in range(min(k, len(relevant)))])\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision@k': precision,\n",
    "        'recall@k': recall,\n",
    "        'ndcg@k': ndcg,\n",
    "        'f1@k': 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    }\n",
    "\n",
    "# Evaluate on test set\n",
    "k_values = [5, 10, 20, 50]\n",
    "all_metrics = {k: {'precision': [], 'recall': [], 'ndcg': []} for k in k_values}\n",
    "\n",
    "# Sample 100 users from test set\n",
    "test_users = test_df['user_id'].unique()[:100]\n",
    "\n",
    "for user_id in test_users:\n",
    "    # Get user's test items\n",
    "    user_test_items = test_df[test_df['user_id'] == user_id]['item_id'].values\n",
    "    \n",
    "    if len(user_test_items) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get recommendations\n",
    "    user_emb = user_embeddings[user_id]\n",
    "    candidate_items, _ = get_top_k_similar_items(user_emb, item_embeddings, k=max(k_values))\n",
    "    \n",
    "    # Compute metrics for different k values\n",
    "    for k in k_values:\n",
    "        metrics = compute_metrics(candidate_items, user_test_items, k=k)\n",
    "        all_metrics[k]['precision'].append(metrics['precision@k'])\n",
    "        all_metrics[k]['recall'].append(metrics['recall@k'])\n",
    "        all_metrics[k]['ndcg'].append(metrics['ndcg@k'])\n",
    "\n",
    "# Aggregate results\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'K': k,\n",
    "        'Precision@K': np.mean(all_metrics[k]['precision']),\n",
    "        'Recall@K': np.mean(all_metrics[k]['recall']),\n",
    "        'NDCG@K': np.mean(all_metrics[k]['ndcg'])\n",
    "    }\n",
    "    for k in k_values\n",
    "])\n",
    "\n",
    "print(\"\\nüìä Evaluation Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize metrics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "metrics_to_plot = ['Precision@K', 'Recall@K', 'NDCG@K']\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    axes[i].plot(results_df['K'], results_df[metric], marker='o', linewidth=2, markersize=8)\n",
    "    axes[i].set_xlabel('K (Number of Recommendations)')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].set_title(metric, fontsize=12, fontweight='bold')\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interview Insight:\")\n",
    "print(\"NDCG is preferred over Precision/Recall because it accounts for position.\")\n",
    "print(\"Top-ranked items matter more - NDCG penalizes placing relevant items lower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£ Business Logic & Diversity\n",
    "\n",
    "### Interview Topic: Why post-processing?\n",
    "- Model optimizes for engagement, not business goals\n",
    "- Need diversity to avoid filter bubbles\n",
    "- Boost fresh content\n",
    "- Remove recently shown items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_diversity_rules(item_ids, scores, max_similar=3):\n",
    "    \"\"\"\n",
    "    Apply diversity using sliding window approach\n",
    "    \n",
    "    Interview Point: Diversity vs Relevance trade-off\n",
    "    - Too diverse ‚Üí lower engagement\n",
    "    - Too similar ‚Üí filter bubble\n",
    "    - Sweet spot: 10-20% diversity boost\n",
    "    \"\"\"\n",
    "    # Simulate categories (in production, fetch from metadata)\n",
    "    categories = {item_id: item_id % 10 for item_id in item_ids}\n",
    "    \n",
    "    diverse_items = []\n",
    "    diverse_scores = []\n",
    "    category_counts = {}\n",
    "    \n",
    "    for item_id, score in zip(item_ids, scores):\n",
    "        category = categories[item_id]\n",
    "        count = category_counts.get(category, 0)\n",
    "        \n",
    "        if count < max_similar:\n",
    "            diverse_items.append(item_id)\n",
    "            diverse_scores.append(score)\n",
    "            category_counts[category] = count + 1\n",
    "    \n",
    "    return diverse_items, diverse_scores\n",
    "\n",
    "# Apply diversity\n",
    "diverse_items, diverse_scores = apply_diversity_rules(\n",
    "    candidate_items, \n",
    "    candidate_scores, \n",
    "    max_similar=3\n",
    ")\n",
    "\n",
    "print(f\"üìä Diversity Impact:\")\n",
    "print(f\"  - Before: {len(candidate_items)} items\")\n",
    "print(f\"  - After:  {len(diverse_items)} items\")\n",
    "print(f\"  - Filtered: {len(candidate_items) - len(diverse_items)} items\")\n",
    "\n",
    "# Compare score distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].hist(candidate_scores, bins=20, alpha=0.7, color='steelblue')\n",
    "axes[0].set_title('Before Diversity Filter', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].hist(diverse_scores, bins=20, alpha=0.7, color='coral')\n",
    "axes[1].set_title('After Diversity Filter', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è‚É£ Monitoring & Data Drift Detection\n",
    "\n",
    "### Interview Topic: Why monitor ML models?\n",
    "- Data distribution changes over time\n",
    "- Model performance degrades\n",
    "- Need to trigger retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psi(baseline, current, bins=10):\n",
    "    \"\"\"\n",
    "    Population Stability Index (PSI)\n",
    "    \n",
    "    Interpretation:\n",
    "    - PSI < 0.1: No significant change\n",
    "    - 0.1 < PSI < 0.2: Moderate change\n",
    "    - PSI > 0.2: Significant drift ‚Üí RETRAIN!\n",
    "    \n",
    "    Interview Point: Industry standard for drift detection\n",
    "    \"\"\"\n",
    "    # Create bins\n",
    "    breakpoints = np.percentile(baseline, np.linspace(0, 100, bins + 1))\n",
    "    breakpoints = np.unique(breakpoints)\n",
    "    \n",
    "    # Count samples in each bin\n",
    "    baseline_counts = np.histogram(baseline, bins=breakpoints)[0]\n",
    "    current_counts = np.histogram(current, bins=breakpoints)[0]\n",
    "    \n",
    "    # Convert to percentages\n",
    "    baseline_pct = baseline_counts / len(baseline)\n",
    "    current_pct = current_counts / len(current)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    baseline_pct = np.where(baseline_pct == 0, 0.0001, baseline_pct)\n",
    "    current_pct = np.where(current_pct == 0, 0.0001, current_pct)\n",
    "    \n",
    "    # Calculate PSI\n",
    "    psi = np.sum((current_pct - baseline_pct) * np.log(current_pct / baseline_pct))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "# Simulate drift\n",
    "baseline_data = np.random.normal(0, 1, 10000)\n",
    "no_drift_data = np.random.normal(0, 1, 10000)\n",
    "moderate_drift_data = np.random.normal(0.2, 1, 10000)\n",
    "significant_drift_data = np.random.normal(0.5, 1.2, 10000)\n",
    "\n",
    "psi_no_drift = compute_psi(baseline_data, no_drift_data)\n",
    "psi_moderate = compute_psi(baseline_data, moderate_drift_data)\n",
    "psi_significant = compute_psi(baseline_data, significant_drift_data)\n",
    "\n",
    "print(\"üìä PSI Drift Detection Examples:\")\n",
    "print(f\"  - No drift:         PSI = {psi_no_drift:.4f} {'‚úÖ OK' if psi_no_drift < 0.1 else ''}\")\n",
    "print(f\"  - Moderate drift:   PSI = {psi_moderate:.4f} {'‚ö†Ô∏è  Monitor' if 0.1 <= psi_moderate < 0.2 else ''}\")\n",
    "print(f\"  - Significant drift: PSI = {psi_significant:.4f} {'üö® RETRAIN!' if psi_significant >= 0.2 else ''}\")\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Baseline\n",
    "axes[0, 0].hist(baseline_data, bins=50, alpha=0.7, color='gray', label='Baseline')\n",
    "axes[0, 0].set_title('Baseline Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# No drift\n",
    "axes[0, 1].hist(baseline_data, bins=50, alpha=0.5, color='gray', label='Baseline')\n",
    "axes[0, 1].hist(no_drift_data, bins=50, alpha=0.5, color='green', label='Current')\n",
    "axes[0, 1].set_title(f'No Drift (PSI={psi_no_drift:.4f})', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Moderate drift\n",
    "axes[1, 0].hist(baseline_data, bins=50, alpha=0.5, color='gray', label='Baseline')\n",
    "axes[1, 0].hist(moderate_drift_data, bins=50, alpha=0.5, color='orange', label='Current')\n",
    "axes[1, 0].set_title(f'Moderate Drift (PSI={psi_moderate:.4f})', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Significant drift\n",
    "axes[1, 1].hist(baseline_data, bins=50, alpha=0.5, color='gray', label='Baseline')\n",
    "axes[1, 1].hist(significant_drift_data, bins=50, alpha=0.5, color='red', label='Current')\n",
    "axes[1, 1].set_title(f'Significant Drift (PSI={psi_significant:.4f})', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9Ô∏è‚É£ A/B Testing Framework\n",
    "\n",
    "### Interview Topic: Statistical rigor in experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def analyze_ab_test(control_conversions, control_samples, \n",
    "                    treatment_conversions, treatment_samples):\n",
    "    \"\"\"\n",
    "    Analyze A/B test results\n",
    "    \n",
    "    Interview Points:\n",
    "    - Sample size matters (don't stop early!)\n",
    "    - Statistical significance ‚â† business significance\n",
    "    - Multiple testing correction\n",
    "    \"\"\"\n",
    "    control_rate = control_conversions / control_samples\n",
    "    treatment_rate = treatment_conversions / treatment_samples\n",
    "    \n",
    "    # Relative lift\n",
    "    relative_lift = (treatment_rate - control_rate) / control_rate if control_rate > 0 else 0\n",
    "    \n",
    "    # Z-test for proportions\n",
    "    pooled_rate = (control_conversions + treatment_conversions) / (control_samples + treatment_samples)\n",
    "    se = np.sqrt(pooled_rate * (1 - pooled_rate) * (1/control_samples + 1/treatment_samples))\n",
    "    z_score = (treatment_rate - control_rate) / se if se > 0 else 0\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "    \n",
    "    # Confidence interval\n",
    "    se_diff = np.sqrt(\n",
    "        control_rate * (1 - control_rate) / control_samples +\n",
    "        treatment_rate * (1 - treatment_rate) / treatment_samples\n",
    "    )\n",
    "    ci_lower = (treatment_rate - control_rate) - 1.96 * se_diff\n",
    "    ci_upper = (treatment_rate - control_rate) + 1.96 * se_diff\n",
    "    \n",
    "    return {\n",
    "        'control_rate': control_rate,\n",
    "        'treatment_rate': treatment_rate,\n",
    "        'relative_lift': relative_lift,\n",
    "        'p_value': p_value,\n",
    "        'is_significant': p_value < 0.05,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    }\n",
    "\n",
    "# Example A/B test\n",
    "results = analyze_ab_test(\n",
    "    control_conversions=300,\n",
    "    control_samples=10000,\n",
    "    treatment_conversions=350,\n",
    "    treatment_samples=10000\n",
    ")\n",
    "\n",
    "print(\"\\nüß™ A/B Test Results:\")\n",
    "print(f\"  Control CTR:     {results['control_rate']*100:.2f}%\")\n",
    "print(f\"  Treatment CTR:   {results['treatment_rate']*100:.2f}%\")\n",
    "print(f\"  Relative Lift:   {results['relative_lift']*100:+.2f}%\")\n",
    "print(f\"  P-value:         {results['p_value']:.4f}\")\n",
    "print(f\"  Significant?     {'‚úÖ YES' if results['is_significant'] else '‚ùå NO'}\")\n",
    "print(f\"  95% CI:          [{results['ci_lower']*100:.2f}%, {results['ci_upper']*100:.2f}%]\")\n",
    "\n",
    "if results['is_significant'] and results['relative_lift'] > 0:\n",
    "    print(\"\\nüöÄ Recommendation: SHIP the treatment variant!\")\n",
    "else:\n",
    "    print(\"\\n‚è∏Ô∏è  Recommendation: Do NOT ship. Keep control.\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "variants = ['Control', 'Treatment']\n",
    "rates = [results['control_rate']*100, results['treatment_rate']*100]\n",
    "colors = ['steelblue', 'coral']\n",
    "\n",
    "bars = ax.bar(variants, rates, color=colors, alpha=0.7)\n",
    "ax.set_ylabel('Conversion Rate (%)')\n",
    "ax.set_title('A/B Test Results', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, rate in zip(bars, rates):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{rate:.2f}%',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Interview Summary\n",
    "\n",
    "### Key Talking Points You Can Now Discuss:\n",
    "\n",
    "1. **System Architecture**\n",
    "   - ‚úÖ Two-stage retrieval (candidate generation + ranking)\n",
    "   - ‚úÖ Why it scales to billions\n",
    "   - ‚úÖ Latency optimization strategies\n",
    "\n",
    "2. **Data & Features**\n",
    "   - ‚úÖ Time-based train/test split (no leakage!)\n",
    "   - ‚úÖ Feature engineering for mixed data types\n",
    "   - ‚úÖ Handling sparsity and power-law distributions\n",
    "\n",
    "3. **Models**\n",
    "   - ‚úÖ Matrix Factorization (baseline)\n",
    "   - ‚úÖ Two-tower neural network (industry standard)\n",
    "   - ‚úÖ When to use what model\n",
    "\n",
    "4. **Production**\n",
    "   - ‚úÖ Embedding generation and ANN search\n",
    "   - ‚úÖ Business logic and diversity\n",
    "   - ‚úÖ Monitoring and drift detection\n",
    "   - ‚úÖ A/B testing framework\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Review `INTERVIEW_GUIDE.md` for specific questions\n",
    "2. Study `CHEAT_SHEET.md` for quick reference\n",
    "3. Practice explaining each component\n",
    "4. Run this notebook multiple times, experiment with parameters\n",
    "\n",
    "---\n",
    "\n",
    "**You're now ready for your staff-level ML interview!** üöÄ\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
