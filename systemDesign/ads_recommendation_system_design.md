# ML System Design Interview: Ads Recommendation System
## Senior / Staff MLE â€” FAANG-Level Interview

---

## Interview Transcript & Solution

---

### ğŸ™ï¸ Interviewer

> "Design an Ads Recommendation System for a large-scale platform â€” think Meta, Google, or TikTok. The system should decide which ad to show to a given user in a given context. Walk me through the full end-to-end ML system."

---

### Step 1: Clarifying Questions

**Candidate:** Before I dive in, I'd like to clarify a few things to scope the problem correctly.

**Candidate:**
- **What is the platform surface?** Is this a social media feed (like Facebook/Instagram), a search results page (like Google), or a video platform (like YouTube/TikTok)?
- **What's the scale?** How many users, how many ads in the inventory, and what's the QPS we're targeting?
- **What's the primary business objective?** Are we optimizing for revenue (eCPM), user experience (engagement + relevance), or a blend?
- **Do we have historical data?** Click logs, conversion logs, user profiles, ad metadata?

**Interviewer:** Let's say it's a social media feed â€” similar to Facebook or Instagram. Assume 2B+ monthly active users, millions of active ad campaigns, ~500K QPS at peak. We want to maximize revenue while maintaining user experience quality. Yes, you have rich historical data.

**Candidate:** Perfect. Let me structure my answer across these key areas:

1. Problem Formulation & Metrics
2. High-Level System Architecture
3. Data & Feature Engineering
4. Model Architecture (Multi-Stage)
5. Training Pipeline
6. Serving Architecture
7. Experimentation & Monitoring

---

### Step 2: Problem Formulation & Metrics

**Candidate:** Let me start by clearly defining what we're optimizing and how we'll measure success.

#### Business Objective

The core objective is to **maximize total ad revenue** while maintaining a healthy user experience. Revenue in an ads system is driven by:

```
Revenue = Î£ (bid Ã— P(click) Ã— P(conversion | click))
        = Î£ (eCPM)
```

So our ML task is to **accurately predict the probability of user engagement** (click, conversion, etc.) for each (user, ad, context) triple.

#### ML Task Decomposition

I'd decompose this into a multi-task prediction problem:

| Task | Label | Model Output |
|------|-------|-------------|
| Click-Through Rate (CTR) | Did user click? (0/1) | P(click) |
| Conversion Rate (CVR) | Did user convert post-click? (0/1) | P(conversion \| click) |
| Engagement Quality | Did user hide/report ad? (0/1) | P(negative feedback) |
| Long-term Value | Did user return / LTV impact? | Estimated value score |

#### Metrics

**Offline Metrics:**
- AUC-ROC and AUC-PR for CTR and CVR models
- Normalized Cross-Entropy (NCE) â€” critical for calibration
- Calibration plots (predicted vs. actual rates)
- NDCG for ranking quality

**Online Metrics:**
- Revenue per 1000 impressions (RPM)
- Click-through rate
- Conversion rate
- User negative feedback rate (hide, report)
- Ad load sensitivity (ads per session)
- Long-term user retention (guardrail)

**Candidate:** Calibration is absolutely critical here â€” unlike pure ranking, ads systems need well-calibrated probabilities because they're multiplied by bids in the auction. A model with great AUC but poor calibration can destroy revenue.

**Interviewer:** Good. That's an important nuance. Walk me through the architecture.

---

### Step 3: High-Level System Architecture

**Candidate:** The system follows a classic **multi-stage funnel architecture** to handle the scale constraint. We can't run a heavyweight model on millions of ad candidates per request.

#### Multi-Stage Funnel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AD REQUEST (User + Context)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: AD RETRIEVAL / CANDIDATE GENERATION                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Targeting   â”‚  â”‚  Embedding   â”‚  â”‚  Inverted Index       â”‚  â”‚
â”‚  â”‚  Filters     â”‚  â”‚  ANN Search  â”‚  â”‚  (Keyword/Interest)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  Millions of ads  â†’â†’â†’  ~10,000 candidates                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: PRE-RANKING / LIGHTWEIGHT SCORING                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Lightweight Model (Two-Tower / Logistic Regression)     â”‚   â”‚
â”‚  â”‚  Fast inference, coarse-grained features                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  ~10,000 candidates  â†’â†’â†’  ~500 candidates                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: RANKING / HEAVY MODEL                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Deep Neural Network (Multi-Task)                        â”‚   â”‚
â”‚  â”‚  Rich cross-features, attention, DCN-v2                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  ~500 candidates  â†’â†’â†’  ~50 scored candidates                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: AUCTION & RE-RANKING                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  eCPM = bid Ã— pCTR Ã— pCVR                               â”‚   â”‚
â”‚  â”‚  + Ad quality score                                      â”‚   â”‚
â”‚  â”‚  + Diversity / Pacing / Budget constraints                â”‚   â”‚
â”‚  â”‚  + Negative feedback penalty                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  ~50 candidates  â†’â†’â†’  3-5 ads placed in feed                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interviewer:** Why four stages and not just one powerful model?

**Candidate:** Pure latency and compute economics. At 500K QPS with millions of ad candidates per request, the math doesn't work for a single heavy model. Each stage trades off model complexity for throughput:

| Stage | Candidates | Latency Budget | Model Complexity |
|-------|-----------|---------------|-----------------|
| Retrieval | Millions â†’ 10K | <10ms | ANN / simple rules |
| Pre-Ranking | 10K â†’ 500 | <5ms per ad | Lightweight NN |
| Ranking | 500 â†’ 50 | <10ms per ad | Deep multi-task NN |
| Auction | 50 â†’ 3-5 | <2ms | Business logic + LP |

Total end-to-end latency target: **< 100ms** at p99.

---

### Step 4: Data & Feature Engineering

**Candidate:** Features are the lifeblood of an ads system. Let me break them down by category.

#### Feature Taxonomy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FEATURE CATEGORIES                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   USER FEATURES  â”‚   AD FEATURES    â”‚   CONTEXT FEATURES           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Demographics   â”‚ â€¢ Ad creative    â”‚ â€¢ Time of day / day of week  â”‚
â”‚   (age, gender,  â”‚   (image embed., â”‚ â€¢ Device type (mobile/web)   â”‚
â”‚    location)     â”‚    text embed.)  â”‚ â€¢ Position in feed           â”‚
â”‚ â€¢ Interest graph â”‚ â€¢ Advertiser ID  â”‚ â€¢ Network type (wifi/LTE)    â”‚
â”‚ â€¢ Behavioral     â”‚ â€¢ Category/Topic â”‚ â€¢ Feed density               â”‚
â”‚   sequences      â”‚ â€¢ Historical CTR â”‚ â€¢ Session depth              â”‚
â”‚ â€¢ Purchase hist. â”‚ â€¢ Landing page   â”‚ â€¢ Preceding content type     â”‚
â”‚ â€¢ Social graph   â”‚   quality score  â”‚ â€¢ Geo-context (home/work)    â”‚
â”‚   embeddings     â”‚ â€¢ Campaign age   â”‚                              â”‚
â”‚ â€¢ Engagement     â”‚ â€¢ Budget pacing  â”‚                              â”‚
â”‚   patterns       â”‚   ratio          â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   CROSS FEATURES          â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ â€¢ User-Ad affinity score  â”‚
                    â”‚ â€¢ UserÃ—Category history   â”‚
                    â”‚ â€¢ UserÃ—Advertiser history â”‚
                    â”‚ â€¢ UserÃ—Creative-type pref â”‚
                    â”‚ â€¢ Social proof features   â”‚
                    â”‚   (did friends engage?)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key Feature Engineering Decisions

**Real-time features** (computed at serving time):
- User's last N actions in current session (sequence features)
- Time since last ad impression (ad fatigue signal)
- Current session engagement rate

**Near-real-time features** (updated every few minutes):
- Ad's rolling CTR over last 1h/6h/24h
- User's rolling engagement stats
- Campaign budget utilization ratio

**Batch features** (updated daily):
- User embeddings from social graph
- Long-term interest profiles
- Advertiser quality scores

**Candidate:** A critical design decision is the **feature store architecture**. I'd use a dual-layer feature store:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FEATURE STORE ARCHITECTURE           â”‚
â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   ONLINE STORE      â”‚   â”‚   OFFLINE STORE   â”‚  â”‚
â”‚  â”‚   (Redis / RocksDB) â”‚   â”‚   (Hive / S3)     â”‚  â”‚
â”‚  â”‚                     â”‚   â”‚                    â”‚  â”‚
â”‚  â”‚  â€¢ p99 < 5ms reads  â”‚   â”‚  â€¢ Training data   â”‚  â”‚
â”‚  â”‚  â€¢ User features    â”‚   â”‚  â€¢ Feature backfillâ”‚  â”‚
â”‚  â”‚  â€¢ Real-time stats  â”‚   â”‚  â€¢ Point-in-time   â”‚  â”‚
â”‚  â”‚  â€¢ Pre-computed     â”‚   â”‚    correctness     â”‚  â”‚
â”‚  â”‚    embeddings       â”‚   â”‚                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                        â”‚              â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                      â”‚                            â”‚
â”‚            Feature consistency                    â”‚
â”‚            (train-serve skew prevention)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interviewer:** How do you handle the train-serve skew problem?

**Candidate:** This is one of the biggest practical challenges. Three strategies:

1. **Log-and-replay**: At serving time, we log the exact feature values used for each prediction alongside the impression. Training data is constructed from these logged features â€” guaranteeing what the model sees in training matches production exactly.

2. **Point-in-time joins**: For batch features, we timestamp everything and do temporal joins so that training examples only use features available at that timestamp.

3. **Feature monitoring**: Continuous distribution monitoring (PSI, KL-divergence) between training and serving feature distributions, with automated alerts.

---

### Step 5: Model Architecture (The Ranking Model â€” Stage 3)

**Candidate:** The ranking model is where the main ML innovation lives. I'd use a **Multi-Task Deep Neural Network** with several key architectural components.

#### Overall Model Architecture

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  P(click)    â”‚  â”‚  P(convert)  â”‚
                        â”‚  (CTR head)  â”‚  â”‚  (CVR head)  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                  â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Task-specificâ”‚  â”‚Task-specific â”‚
                        â”‚  Tower (MLP) â”‚  â”‚Tower (MLP)   â”‚
                        â”‚  [256â†’128â†’64]â”‚  â”‚[256â†’128â†’64]  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                  â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  SHARED BOTTOM   â”‚
                               â”‚  NETWORK         â”‚
                               â”‚                  â”‚
                               â”‚  MMoE Layer      â”‚
                               â”‚  (Multi-gate     â”‚
                               â”‚   Mixture of     â”‚
                               â”‚   Experts)       â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”´â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚ â”‚                   â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  DCN-v2     â”‚  â”‚  Deep Network    â”‚  â”‚  Sequence Model â”‚
             â”‚  (Cross     â”‚  â”‚  (MLP tower)     â”‚  â”‚  (Transformer / â”‚
             â”‚   Network)  â”‚  â”‚  [1024â†’512â†’256]  â”‚  â”‚   DIN / DIEN)   â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                  â”‚                      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  EMBEDDING LAYER  â”‚
                              â”‚                   â”‚
                              â”‚  Sparse features  â”‚
                              â”‚  â†’ Embeddings     â”‚
                              â”‚  (dim: 16-64)     â”‚
                              â”‚                   â”‚
                              â”‚  Dense features   â”‚
                              â”‚  â†’ Normalization  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          â”‚        â”‚        â”‚          â”‚
                â”Œâ”€â”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”´â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”
                â”‚ User  â”‚ â”‚  Ad   â”‚ â”‚Crossâ”‚ â”‚Ctx  â”‚  â”‚Sequenceâ”‚
                â”‚Featuresâ”‚ â”‚Featuresâ”‚ â”‚Featsâ”‚ â”‚Featsâ”‚  â”‚Featuresâ”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key Architectural Choices & Rationale

**1. Multi-Gate Mixture of Experts (MMoE)**

**Candidate:** I chose MMoE over a simple shared-bottom because CTR and CVR tasks have related but distinct data distributions. MMoE lets each task learn its own gating weights over shared expert sub-networks, giving better task-specific specialization while still sharing useful representations.

```
        Gate_CTR    Gate_CVR
        [w1,w2,w3]  [w1,w2,w3]
            â”‚            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       â”‚            â”‚       â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â” â”Œâ”´â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”´â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”
â”‚Expert1â”‚ â”‚Exp.2â”‚  â”‚Exp.3â”‚ â”‚Expert4â”‚
â”‚(MLP)  â”‚ â”‚(MLP)â”‚  â”‚(MLP)â”‚ â”‚(MLP)  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
           Shared Input
```

**2. DCN-v2 (Deep & Cross Network v2)**

For explicit feature interactions. Unlike raw MLPs which learn interactions implicitly, DCN-v2 explicitly models bounded-degree feature crosses â€” critical for capturing patterns like "users aged 25-34 in tech industry respond well to SaaS ads on weekday mornings."

**3. Deep Interest Network (DIN) / DIEN for Sequences**

User behavior sequences (last 50 ad interactions) are processed with attention mechanisms where the **candidate ad attends over the user's historical interactions**, giving adaptive user representations that are ad-aware.

```
Attention Score = softmax(Ad_embedding Â· History_i_embedding)

User_representation = Î£(attention_i Ã— history_embedding_i)
```

This is far superior to average-pooling because it activates different parts of user history depending on which ad is being scored.

**Interviewer:** How do you handle the CVR prediction given that conversions only happen post-click? That's a sample selection bias problem.

**Candidate:** Excellent question. This is a well-known problem â€” if we only train CVR on clicked samples, the model is biased because the click itself is a confounding filter.

I'd use the **ESMM (Entire Space Multi-Task Model)** approach:

```
                P(click AND convert)
P(convert|click) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                       P(click)

So we model:
  â€¢ pCTR from the CTR tower
  â€¢ pCTCVR = P(click AND convert) jointly
  â€¢ pCVR = pCTCVR / pCTR

Key insight: pCTCVR is trained on ALL impressions (not just clicks),
which eliminates the sample selection bias.
```

The CVR tower's parameters are trained via the pCTCVR loss computed over the entire impression space, while the final pCVR is derived by division at inference.

---

### Step 6: Training Pipeline

**Candidate:** Let me walk through the training infrastructure.

#### Training Data Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ad Serving  â”‚â”€â”€â”€â”€â–¶â”‚  Impression  â”‚â”€â”€â”€â”€â–¶â”‚  Join with        â”‚
â”‚  Logs        â”‚     â”‚  Logger      â”‚     â”‚  Downstream Labelsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  (click/convert   â”‚
                                          â”‚   within windows) â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚  Feature Snapshot   â”‚
                                          â”‚  (logged features + â”‚
                                          â”‚   point-in-time     â”‚
                                          â”‚   batch features)   â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚  Training Data      â”‚
                                          â”‚  Pipeline           â”‚
                                          â”‚  (negative sampling,â”‚
                                          â”‚   deduplication,    â”‚
                                          â”‚   data validation)  â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                     â–¼                  â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Full Retrainâ”‚      â”‚ Incremental  â”‚    â”‚ Real-time    â”‚
                     â”‚ (Weekly)    â”‚      â”‚ (Daily)      â”‚    â”‚ (Streaming)  â”‚
                     â”‚ All data    â”‚      â”‚ Last N days  â”‚    â”‚ Online learn â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Training Strategy

**Candidate:** A few critical decisions:

**a) Loss Function:**
```
L_total = Î± Â· L_CTR(BCE) + Î² Â· L_CTCVR(BCE) + Î³ Â· L_neg_feedback(BCE) + Î» Â· L_calibration

Where calibration loss ensures predicted probabilities match observed rates
in bucketed segments.
```

**b) Training Cadence:**
- **Full retrain weekly** on 30 days of data â€” resets model from scratch
- **Daily incremental warm-start** â€” fine-tune from the last checkpoint on the latest day's data
- **Optional: Online learning** with streaming updates for ultra-fresh user signals (but adds complexity and instability risk)

**c) Label Attribution Window:**
- Click: attributed within 30 seconds of impression
- Conversion: attributed within 7-day window post-click
- This means training data for CVR is delayed by 7 days (stale label problem)

**Candidate:** The stale label problem is significant. A practical solution is to use a **label correction model** or **importance weighting** where recent but incomplete labels are reweighted based on historical conversion delay curves.

**d) Handling Class Imbalance:**
- CTR is typically ~2-5%, CVR ~1-3% of clicks
- Use **negative downsampling** during training (e.g., keep 10% of negatives)
- Apply **calibration correction** at serving: `p_calibrated = p / (p + (1-p)/w)` where w is the downsampling rate

---

### Step 7: Serving Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVING INFRASTRUCTURE                          â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Client   â”‚â”€â”€â”€â–¶â”‚  Ad Request  â”‚â”€â”€â”€â–¶â”‚  Feature Assembly     â”‚    â”‚
â”‚  â”‚  (App)    â”‚    â”‚  Router      â”‚    â”‚  Service               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚                                       â”‚  â”‚ Online Feature   â”‚ â”‚    â”‚
â”‚                                       â”‚  â”‚ Store (Redis)    â”‚ â”‚    â”‚
â”‚                                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚                                       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚                                       â”‚  â”‚ Real-time Featureâ”‚ â”‚    â”‚
â”‚                                       â”‚  â”‚ Compute          â”‚ â”‚    â”‚
â”‚                                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                   â”‚                â”‚
â”‚                                                   â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚               MODEL SERVING LAYER                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚ Retrieval  â”‚â”€â–¶â”‚ Pre-Ranker  â”‚â”€â–¶â”‚ Heavy Ranker   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚ (FAISS/    â”‚  â”‚ (TF-Serving)â”‚  â”‚ (TF-Serving /  â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  ScaNN)    â”‚  â”‚             â”‚  â”‚  Triton)       â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                                           â”‚               â”‚    â”‚
â”‚  â”‚              GPU Cluster (batched inference)               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                              â”‚                    â”‚
â”‚                                              â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚               AUCTION ENGINE                              â”‚    â”‚
â”‚  â”‚  â€¢ eCPM scoring    â€¢ Budget pacing   â€¢ Frequency caps     â”‚    â”‚
â”‚  â”‚  â€¢ Diversity rules  â€¢ Policy filters  â€¢ Ad quality gates  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                          â”‚                        â”‚
â”‚                                          â–¼                        â”‚
â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                                   â”‚  Response:   â”‚                â”‚
â”‚                                   â”‚  Top K Ads   â”‚                â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Serving Optimizations

**Candidate:** At 500K QPS, every millisecond matters. Key optimizations:

1. **Model quantization**: INT8 quantization for the embedding tables (which dominate model size) â€” reduces memory 4x with <0.1% AUC loss.

2. **Batched GPU inference**: Batch requests on the GPU side to maximize throughput. Dynamic batching with timeout to trade latency for throughput.

3. **Pre-computed user embeddings**: The user tower of the two-tower model is independent of the ad â€” compute it once per request and reuse across all ad candidates.

4. **Embedding table sharding**: The embedding tables for sparse features (user IDs, ad IDs) can be hundreds of GB. Shard across multiple servers with an embedding lookup service.

5. **Cascading timeout**: If the heavy ranker times out, fall back to pre-ranker scores rather than returning no ads.

---

### Step 8: Auction Mechanism

**Candidate:** The auction is where ML meets business logic.

#### Generalized Second-Price (GSP) â†’ VCG-style Auction

```
For each ad slot position k:

  Score(ad_i) = bid_i Ã— pCTR_i Ã— pCVR_i Ã— quality_i - penalty_i

  Where:
    bid_i        = advertiser's bid (CPC or CPA)
    pCTR_i       = predicted click-through rate
    pCVR_i       = predicted conversion rate
    quality_i    = ad creative quality score (0.8 - 1.2 multiplier)
    penalty_i    = negative feedback prediction Ã— penalty weight

  Winner pays: Score(2nd place) / pCTR_winner  (GSP pricing)
```

**Key business constraints applied post-ranking:**
- **Budget pacing**: Smooth delivery across the day (don't blow budget at 9am)
- **Frequency capping**: Max N impressions per user per ad per day
- **Diversity**: Don't show 3 ads from the same advertiser in sequence
- **Policy compliance**: Filter out policy-violating ads

---

### Step 9: Experimentation & Monitoring

**Candidate:** This is where many systems fail in practice.

#### A/B Testing Framework

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 A/B TESTING PIPELINE                      â”‚
â”‚                                                          â”‚
â”‚   User traffic                                           â”‚
â”‚       â”‚                                                  â”‚
â”‚       â–¼                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚   â”‚  Hash-based bucket â”‚                                 â”‚
â”‚   â”‚  (user_id mod N)   â”‚                                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚            â”‚                                             â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”                                       â”‚
â”‚      â–¼     â–¼     â–¼                                       â”‚
â”‚   Control  Trt1  Trt2                                    â”‚
â”‚    (80%)  (10%) (10%)                                    â”‚
â”‚      â”‚     â”‚     â”‚                                       â”‚
â”‚      â–¼     â–¼     â–¼                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚   â”‚  Statistical test: â”‚  Primary: Revenue per user      â”‚
â”‚   â”‚  â€¢ Revenue lift    â”‚  Guardrail: NPS, retention,     â”‚
â”‚   â”‚  â€¢ Confidence      â”‚            negative feedback    â”‚
â”‚   â”‚  â€¢ Power analysis  â”‚  Duration: 1-2 weeks            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Real-Time Monitoring Dashboard

**Key monitoring signals:**

| Signal | Frequency | Alert Threshold |
|--------|-----------|----------------|
| Overall CTR | Per-minute | Â±10% from baseline |
| Revenue RPM | Per-minute | Â±15% from baseline |
| Model latency (p50/p99) | Per-second | p99 > 80ms |
| Feature freshness | Per-minute | Staleness > 10min |
| Prediction distribution shift | Hourly | PSI > 0.1 |
| Negative feedback rate | Per-minute | +20% from baseline |
| Serving errors / timeouts | Per-second | > 0.1% error rate |

**Candidate:** I'd also build an **automated circuit breaker**: if the model's prediction distribution shifts dramatically (possibly due to a bad model push or data pipeline failure), automatically roll back to the previous model version.

---

### Step 10: Advanced Topics & Staff-Level Depth

**Interviewer:** You've covered the system well. Let me push you on a few advanced areas.

#### 10a. Cold Start Problem

**Interviewer:** How do you handle new ads with no engagement history?

**Candidate:** Multi-pronged approach:

1. **Content-based features**: Extract features from the ad creative (image embeddings from a pre-trained vision model, text embeddings from BERT/LLM). These generalize to new ads immediately.

2. **Explore-exploit**: Use a Thompson Sampling or Upper Confidence Bound (UCB) approach in the auction. New ads get an exploration bonus that decays as we collect data:

```
exploration_bonus = Î± Ã— sqrt(log(total_impressions) / (ad_impressions + 1))
```

3. **Hierarchical priors**: Share statistics at the advertiser â†’ campaign â†’ ad group level. A new ad from a known advertiser starts with the advertiser's average CTR as a prior, then personalizes with Bayesian updating.

4. **Dedicated exploration budget**: Reserve 5-10% of ad inventory for exploration, ensuring new ads get sufficient impressions to learn from.

#### 10b. Position Bias

**Interviewer:** How do you handle the fact that higher positions in the feed get more clicks regardless of ad quality?

**Candidate:** Position bias is a major confound. I'd address it at both training and serving time:

**Training time**: Use position as an input feature but apply **position debiasing**:
```
P(click) = Ïƒ(f_relevance(user, ad) + g_position(position))

At serving time: set position = default_position for all candidates,
so ranking is based purely on f_relevance.
```

Alternatively, use **inverse propensity weighting (IPW)** where each training example is weighted by 1/P(position | ad was shown there), estimated from position randomization experiments.

#### 10c. Privacy & Personalization Trade-off

**Candidate:** With the deprecation of third-party cookies and increasing privacy regulations (GDPR, CCPA, ATT on iOS), I'd invest in:

1. **On-device models**: Lightweight models that run on the client device using first-party data, sending only encrypted prediction scores to the server.

2. **Federated Learning**: Train on user data without centralizing it. Practical for learning user preferences without raw data leaving the device.

3. **Contextual targeting**: Invest heavily in context features (page content, time, device) that don't require personal data but still provide signal.

4. **Privacy-preserving ML**: Techniques like differential privacy in training, secure aggregation for federated models.

---

### Summary & Closing

**Candidate:** Let me summarize the key design decisions:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DESIGN DECISIONS SUMMARY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Problem Formulation    â”‚ Multi-task: CTR + CVR + neg feedback  â”‚
â”‚ Architecture           â”‚ 4-stage funnel (retrieve â†’ rank)      â”‚
â”‚ Core Model             â”‚ MMoE + DCN-v2 + DIN attention         â”‚
â”‚ Training               â”‚ Weekly full + daily incremental       â”‚
â”‚ Key Innovation         â”‚ ESMM for unbiased CVR estimation      â”‚
â”‚ Serving                â”‚ Batched GPU, INT8, pre-computed embedsâ”‚
â”‚ Auction                â”‚ GSP with quality & penalty modifiers  â”‚
â”‚ Cold Start             â”‚ Explore-exploit + hierarchical priors â”‚
â”‚ Calibration            â”‚ NCE + post-hoc isotonic regression    â”‚
â”‚ Monitoring             â”‚ Real-time PSI + automated rollback    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interviewer:** Great answer. You've demonstrated strong breadth across the full system and depth in critical areas like calibration, CVR bias, and position debiasing. Thank you.

---

*This document represents a Staff/Senior MLE-level system design response covering the full spectrum from problem formulation to production deployment, suitable for FAANG ads ML interviews.*
